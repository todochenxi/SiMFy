import os
import numpy as np
import torch
import scipy.sparse as sp

def get_total_number(inPath, fileName):
    with open(os.path.join(inPath, fileName), 'r') as fr:
        for line in fr:
            line_split = line.split()
            return int(line_split[0]), int(line_split[1]), int(line_split[2])  # å®ä½“ï¼Œå…³ç³»ï¼Œæ—¶é—´ç‚¹çš„ä¸ªæ•°

def load_quadruples(inPath, fileName, num_r):
    quadrupleList = []
    times = set()
    with open(os.path.join(inPath, fileName), 'r') as fr:
        for line in fr:
            line_split = line.split()
            head = int(line_split[0])
            tail = int(line_split[2])
            rel = int(line_split[1])
            time = int(line_split[3])
            quadrupleList.append([head, rel, tail, time])
            times.add(time)
    with open(os.path.join(inPath, fileName), 'r') as fr:
        for line in fr:
            line_split = line.split()
            head = int(line_split[0])
            tail = int(line_split[2])
            rel = int(line_split[1])
            time = int(line_split[3])
            quadrupleList.append([tail, rel + num_r, head, time])
    times = list(times)
    times.sort()
    return np.asarray(quadrupleList), np.asarray(times)

def load_list(inPath, entityDictPath, relationDictPath):
    entity_list = []
    relation_list = []
    with open(os.path.join(inPath, entityDictPath), 'r') as fr:
        for line in fr:
            line_split = line.split()
            # id = int(line_split[-1])
            text = line_split[0]
            if len(line_split) > 2:
                for i in line_split[1:-1]:
                    text += " " + i
            entity_list.append(text)
    with open(os.path.join(inPath, relationDictPath), 'r') as fr:
        for line in fr:
            line_split = line.split()

            # id = int(line_split[-1])

            text = line_split[0]
            if len(line_split) > 2:
                for i in line_split[1:-1]:
                    text += " " + i
            relation_list.append(text)

    return entity_list, relation_list

def get_outputs(dataset, s_list, p_list, t_list, num_rels, k, is_multi_step=False):
    """
    :param dataset: æ•°æ®é›†
    :param s_list: å¤´å®ä½“åˆ—è¡¨
    :param p_list: å…³ç³»åˆ—è¡¨
    :param t_list: æ—¶é—´ç‚¹åˆ—è¡¨
    :param num_rels: å…³ç³»æ•°é‡
    :param k: ç¼©æ”¾å› å­
    :param is_multi_step: æ˜¯å¦æ˜¯å¤šæ­¥éª¤å¤„ç†
    :return: è®¡ç®—ç»™å®šæ•°æ®é›†çš„è¾“å‡ºçŸ©é˜µï¼Œç”¨äºæ¨¡å‹é¢„æµ‹å’Œè¯„ä¼°
    """
    outputs = []
    if not is_multi_step:
        freq_graph = sp.load_npz('./data/{}/history_seq/h_r_history_train_valid.npz'.format(dataset))
        for idx in range(len(s_list)):
            s = s_list[idx]
            p = p_list[idx]
            num_r_2 = num_rels * 2
            row = s * num_r_2 + p
            outputs.append(freq_graph[row].toarray()[0] * k)
    else:
        unique_t_list = list(set(t_list))
        tim_seq_dict = {}
        for tim in unique_t_list:
            tim_seq_dict[str(tim)] = sp.load_npz(
                './data/{}/history_seq/all_history_seq_before_{}.npz'.format(dataset, tim))
        for idx in range(len(s_list)):
            s = s_list[idx]
            p = p_list[idx]
            t = t_list[idx]
            num_r_2 = num_rels * 2
            row = s * num_r_2 + p
            outputs.append(tim_seq_dict[str(t)][row].toarray()[0] * k)

    return torch.tensor(outputs)

def sort_and_rank(score, target):
    """
    :param score: åˆ†æ•°å¼ é‡
    :param target: ç›®æ ‡å¼ é‡
    :return: å¯¹é¢„æµ‹ç»“æœè¿›è¡Œæ’åºï¼Œå¹¶ç¡®å®šç›®æ ‡åœ¨æ’åºç»“æœä¸­çš„ä½ç½®
    """
    _, indices = torch.sort(score, dim=1, descending=True)
    indices = torch.nonzero(indices == target.view(-1, 1))  # target.view(-1, 1) å°†ç›®æ ‡å®ä½“ target é‡æ–°å½¢çŠ¶ä¸ºä¸€ä¸ªäºŒç»´å¼ é‡ï¼ˆN, 1ï¼‰ï¼Œç„¶åè¿›è¡Œæ¯”è¾ƒè¿”å›éé›¶å…ƒç´ çš„ç´¢å¼•
    indices = indices[:, 1].view(-1)
    return indices

# return MRR (raw), and Hits @ (1, 3, 10)
def calc_raw_mrr(score, labels, hits=[]):
    """
    :param score: é¢„æµ‹çš„è¯„åˆ†çŸ©é˜µï¼Œå½¢çŠ¶ä¸ºï¼ˆN,Mï¼‰ Næ˜¯æ ·æœ¬æ•°é‡ï¼ŒMæ˜¯å€™é€‰é¡¹çš„æ•°é‡
    :param labels: ç›®æ ‡å®ä½“çš„ç´¢å¼•ï¼Œå½¢çŠ¶ä¸ºï¼ˆN,ï¼‰
    :param hits: Hits@kçš„é˜ˆå€¼åˆ—è¡¨
    :return: mrrï¼šå¹³å‡å€’æ•°æ’å (Mean Reciprocal Rank)ã€‚
            hits1ï¼šHits @ 1ï¼Œå³ç›®æ ‡é¡¹åœ¨å‰ 1 åä¸­çš„æ¯”ä¾‹ã€‚
            hits3ï¼šHits @ 3ï¼Œå³ç›®æ ‡é¡¹åœ¨å‰ 3 åä¸­çš„æ¯”ä¾‹
            hits10ï¼šHits @ 10ï¼Œå³ç›®æ ‡é¡¹åœ¨å‰ 10 åä¸­çš„æ¯”ä¾‹
    MRRï¼ˆMean Reciprocal Rankï¼Œå¹³å‡å€’æ•°æ’åï¼‰æ˜¯ä¸€ç§ç”¨äºè¯„ä¼°ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿå’Œæ¨èç³»ç»Ÿçš„æŒ‡æ ‡ã€‚å®ƒè¡¡é‡çš„æ˜¯ç›®æ ‡é¡¹åœ¨é¢„æµ‹æ’åºä¸­çš„æ’åçš„å€’æ•°çš„å¹³å‡å€¼ã€‚å…¶è®¡ç®—æ–¹å¼å¦‚ä¸‹ï¼š
 ã€‚
1. è®¡ç®—æ¯ä¸ªç›®æ ‡é¡¹çš„æ’åå€’æ•°ï¼š
å¦‚æœç›®æ ‡é¡¹åœ¨ç¬¬ ğ‘˜ä¸ªä½ç½®ä¸Šï¼Œé‚£ä¹ˆå…¶å€’æ•°æ’åæ˜¯ 1/ğ‘˜
2. è®¡ç®—æ‰€æœ‰ç›®æ ‡é¡¹çš„å€’æ•°æ’åçš„å¹³å‡å€¼ï¼š
å¯¹æ‰€æœ‰ç›®æ ‡é¡¹çš„å€’æ•°æ’åå–å¹³å‡å€¼ï¼Œå¾—åˆ° MRRã€‚
MRR çš„å€¼èŒƒå›´æ˜¯ (0, 1]ï¼Œè¶Šæ¥è¿‘ 1 è¡¨ç¤ºé¢„æµ‹è¶Šå‡†ç¡®ã€‚
    """
    with torch.no_grad():

        ranks = sort_and_rank(score, labels)  # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æ’åï¼Œå´å¯¹ç›®æ ‡æ ·æœ¬åœ¨æ’åºç»“æœä¸­çš„ä½ç½®

        ranks += 1 # change to 1-indexed  # å°†æ’ååŠ 1ï¼Œä½¿å…¶ä»1å¼€å§‹

        mrr = torch.mean(1.0 / ranks.float())  # è®¡ç®—mrr

        hits1 = torch.mean((ranks <= hits[0]).float())
        hits3 = torch.mean((ranks <= hits[1]).float())
        hits10 = torch.mean((ranks <= hits[2]).float())

    return mrr.item(), hits1.item(), hits3.item(), hits10.item()

#######################################################################
#
# Utility functions for evaluations (filtered)
#
#######################################################################

# è¿™ä¸¤ä¸ªå‡½æ•°ç”¨äºåœ¨è¯„ä¼°çŸ¥è¯†å›¾è°±è¡¥å…¨æ¨¡å‹æ—¶ï¼Œå¯¹å€™é€‰çš„å¤´å®ä½“ï¼ˆhï¼‰æˆ–å°¾å®ä½“ï¼ˆtï¼‰è¿›è¡Œè¿‡æ»¤ã€‚è¿‡æ»¤çš„ç›®çš„æ˜¯æ’é™¤è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸­å·²ç»å­˜åœ¨çš„ä¸‰å…ƒç»„ï¼Œ
# ä»¥ä¾¿æ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹åœ¨æœªè§è¿‡çš„ä¸‰å…ƒç»„ä¸Šçš„è¡¨ç°ã€‚
def filter_h(triplets_to_filter, target_h, target_r, target_t, num_entities):
    target_h, target_r, target_t = int(target_h), int(target_r), int(target_t)
    filtered_h = []

    # Do not filter out the test triplet, since we want to predict on it
    if (target_h, target_r, target_t) in triplets_to_filter:
        triplets_to_filter.remove((target_h, target_r, target_t))
    # Do not consider an object if it is part of a triplet to filter
    for h in range(num_entities):
        if (h, target_r, target_t) not in triplets_to_filter:
            filtered_h.append(h)
    return torch.LongTensor(filtered_h)

def filter_t(triplets_to_filter, target_h, target_r, target_t, num_entities):
    target_h, target_r, target_t = int(target_h), int(target_r), int(target_t)
    filtered_t = []

    # Do not filter out the test triplet, since we want to predict on it
    if (target_h, target_r, target_t) in triplets_to_filter:
        triplets_to_filter.remove((target_h, target_r, target_t))
    # Do not consider an object if it is part of a triplet to filter
    for t in range(num_entities):
        if (target_h, target_r, t) not in triplets_to_filter:
            filtered_t.append(t)
    return torch.LongTensor(filtered_t)

# è¿™ä¸ªå‡½æ•° get_filtered_rank ç”¨äºè®¡ç®—åœ¨è¿‡æ»¤åçš„å€™é€‰å®ä½“é›†åˆä¸­ï¼Œç›®æ ‡å®ä½“çš„æ’åã€‚è¿™ä¸ªè¿‡ç¨‹æ˜¯çŸ¥è¯†å›¾è°±è¯„ä¼°çš„ä¸€éƒ¨åˆ†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚
def get_filtered_rank(num_entity, score, h, r, t, test_size, triplets_to_filter, entity):
    """ Perturb object in the triplets
    entityï¼šå­—ç¬¦ä¸²ï¼Œå€¼ä¸º 'object' æˆ– 'subject'ï¼Œè¡¨ç¤ºè¦è®¡ç®—çš„æ˜¯å°¾å®ä½“ï¼ˆobjectï¼‰è¿˜æ˜¯å¤´å®ä½“ï¼ˆsubjectï¼‰çš„æ’åã€‚
    è¿™ä¸ªå‡½æ•°çš„ç›®çš„æ˜¯åœ¨è¯„ä¼°æ¨¡å‹æ—¶ï¼Œè®¡ç®—ç›®æ ‡å®ä½“åœ¨è¿‡æ»¤åçš„å€™é€‰å®ä½“é›†åˆä¸­çš„æ’åã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ›´åŠ å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹åœ¨çŸ¥è¯†å›¾è°±è¡¥å…¨ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œ
    å› ä¸ºå®ƒæ’é™¤äº†é‚£äº›å·²ç»åœ¨è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸­å­˜åœ¨çš„ä¸‰å…ƒç»„çš„å½±å“ã€‚
    """
    num_entities = num_entity
    ranks = []

    for idx in range(test_size):
        target_h = h[idx]
        target_r = r[idx]
        target_t = t[idx]
        # print('t',target_t)
        if entity == 'object':
            filtered_t = filter_t(triplets_to_filter, target_h, target_r, target_t, num_entities)
            target_t_idx = int((filtered_t == target_t).nonzero())
            _, indices = torch.sort(score[idx][filtered_t], descending=True)
            rank = int((indices == target_t_idx).nonzero())
        if entity == 'subject':
            filtered_h = filter_h(triplets_to_filter, target_h, target_r, target_t, num_entities)
            target_h_idx = int((filtered_h == target_h).nonzero())
            _, indices = torch.sort(score[idx][filtered_h], descending=True)
            rank = int((indices == target_h_idx).nonzero())

        ranks.append(rank)
    return torch.LongTensor(ranks)


def calc_filtered_test_mrr(num_entity, score, train_triplets, valid_triplets, valid_triplets2, test_triplets, entity, hits=[]):
    """
    :param num_entity: å®ä½“çš„æ€»æ•°ã€‚
    :param score: æ¨¡å‹è¾“å‡ºçš„å¾—åˆ†çŸ©é˜µï¼Œå½¢çŠ¶ä¸º (test_size, num_entities)ï¼Œè¡¨ç¤ºæ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„æ¯ä¸ªå®ä½“çš„å¾—åˆ†ã€‚
    :param train_triplets:
    :param valid_triplets:
    :param valid_triplets2: ç¬¬äºŒä¸ªéªŒè¯é›†ä¸­çš„ä¸‰å…ƒç»„ï¼ˆå¦‚æœæœ‰ï¼‰ã€‚
    :param test_triplets:
    :param entity: å­—ç¬¦ä¸²ï¼Œå€¼ä¸º 'object' æˆ– 'subject'ï¼Œè¡¨ç¤ºè¦è®¡ç®—çš„æ˜¯å°¾å®ä½“ï¼ˆobjectï¼‰è¿˜æ˜¯å¤´å®ä½“ï¼ˆsubjectï¼‰çš„æ’åã€‚
    :param hits: ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªæ•´æ•°çš„åˆ—è¡¨ï¼Œåˆ†åˆ«è¡¨ç¤º Hits@1, Hits@3 å’Œ Hits@10 çš„è®¡ç®—èŒƒå›´ã€‚
    :return:
    å‡½æ•°è®¡ç®—è¿‡æ»¤åçš„æµ‹è¯•é›†ä¸Šçš„ MRRï¼ˆå¹³å‡å€’æ•°æ’åï¼‰å’Œ Hits@K æŒ‡æ ‡ã€‚è¿™ä¸ªå‡½æ•°ç”¨äºè¯„ä¼°çŸ¥è¯†å›¾è°±åµŒå…¥æ¨¡å‹åœ¨è¿‡æ»¤æ¡ä»¶ä¸‹çš„é¢„æµ‹æ•ˆæœã€‚æ‰€è°“è¿‡æ»¤æ¡ä»¶ï¼Œ
    å³æ’é™¤è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸­å·²ç»å­˜åœ¨çš„ä¸‰å…ƒç»„çš„å½±å“ï¼Œåªè€ƒè™‘æ¨¡å‹åœ¨è¿™äº›æ•°æ®ä¹‹å¤–çš„é¢„æµ‹èƒ½åŠ›ã€‚
    """
    with torch.no_grad():
        # æå–æµ‹è¯•é›†ä¸­çš„å¤´å®ä½“ã€å…³ç³»å’Œå°¾å®ä½“
        h = test_triplets[:, 0]
        r = test_triplets[:, 1]
        t = test_triplets[:, 2]
        test_size = test_triplets.shape[0]
        # å°†è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†çš„ä¸‰å…ƒç»„è½¬æ¢ä¸ºå¼ é‡æ ¼å¼
        train_triplets = torch.Tensor([[quad[0], quad[1], quad[2]] for quad in train_triplets])
        valid_triplets = torch.Tensor([[quad[0], quad[1], quad[2]] for quad in valid_triplets])
        valid_triplets2 = torch.Tensor([[quad[0], quad[1], quad[2]] for quad in valid_triplets2])
        test_triplets = torch.Tensor([[quad[0], quad[1], quad[2]] for quad in test_triplets])
        # åˆå¹¶æ‰€æœ‰ä¸‰å…ƒç»„ï¼Œå¹¶è½¬æ¢ä¸ºé›†åˆå½¢å¼ï¼Œä»¥ä¾¿è¿›è¡Œè¿‡æ»¤
        triplets_to_filter = torch.cat([train_triplets, valid_triplets, valid_triplets2, test_triplets]).tolist()
        triplets_to_filter = {tuple(triplet) for triplet in triplets_to_filter}
        # è®¡ç®—è¿‡æ»¤åçš„æ’å
        ranks = get_filtered_rank(num_entity, score, h, r, t, test_size, triplets_to_filter, entity)
        # å°†æ’åä»0ç´¢å¼•è½¬æ¢ä¸º1ç´¢å¼•
        ranks += 1 # change to 1-indexed
        # è®¡ç®— MRRï¼ˆå¹³å‡å€’æ•°æ’åï¼‰
        mrr = torch.mean(1.0 / ranks.float())
        # è®¡ç®— Hits@1, Hits@3 å’Œ Hits@10
        hits1 = torch.mean((ranks <= hits[0]).float())
        hits3 = torch.mean((ranks <= hits[1]).float())
        hits10 = torch.mean((ranks <= hits[2]).float())

    return mrr.item(), hits1.item(), hits3.item(), hits10.item()

#######################################################################
#
# Utility functions for evaluations (time-aware-filtered) ç”¨äºè¯„ä¼°çš„å®ç”¨å‡½æ•°ï¼ˆæ—¶é—´æ„ŸçŸ¥è¿‡æ»¤ï¼‰
#
#######################################################################

def ta_filter_h(triplets_to_filter, target_h, target_r, target_t, num_entities):
    target_h, target_r, target_t = int(target_h), int(target_r), int(target_t)
    filtered_h = []

    # Do not filter out the test triplet, since we want to predict on it
    if (target_h, target_r, target_t) in triplets_to_filter:
        triplets_to_filter.remove((target_h, target_r, target_t))
    # Do not consider an object if it is part of a triplet to filter
    for h in range(num_entities):
        if (h, target_r, target_t) not in triplets_to_filter:
            filtered_h.append(h)
    return torch.LongTensor(filtered_h)

def ta_filter_t(triplets_to_filter, target_h, target_r, target_t, target_tim, num_entities):
    target_h, target_r, target_t = int(target_h), int(target_r), int(target_t)
    target_tim = int(target_tim)
    filtered_t = []

    # Do not filter out the test triplet, since we want to predict on it
    if (target_h, target_r, target_t, target_tim) in triplets_to_filter:
        triplets_to_filter.remove((target_h, target_r, target_t, target_tim))
    # Do not consider an object if it is part of a triplet to filter
    for t in range(num_entities):
        if (target_h, target_r, t, target_tim) not in triplets_to_filter:
            filtered_t.append(t)
    return torch.LongTensor(filtered_t)

def ta_get_filtered_rank(num_entity, score, h, r, t, tim, test_size, triplets_to_filter, entity):
    """ Perturb object in the triplets
    """
    num_entities = num_entity
    ranks = []

    for idx in range(test_size):
        target_h = h[idx]
        target_r = r[idx]
        target_t = t[idx]
        target_tim = tim[idx]
        # print('t',target_t)
        if entity == 'object':
            filtered_t = ta_filter_t(triplets_to_filter, target_h, target_r, target_t, target_tim, num_entities)
            target_t_idx = int((filtered_t == target_t).nonzero())
            _, indices = torch.sort(score[idx][filtered_t], descending=True)
            rank = int((indices == target_t_idx).nonzero())
        if entity == 'subject':
            filtered_h = ta_filter_h(triplets_to_filter, target_h, target_r, target_t, num_entities)
            target_h_idx = int((filtered_h == target_h).nonzero())
            _, indices = torch.sort(score[idx][filtered_h], descending=True)
            rank = int((indices == target_h_idx).nonzero())

        ranks.append(rank)
    return torch.LongTensor(ranks)


def ta_calc_filtered_test_mrr(num_entity, score, valid_triplets2, test_triplets, entity, hits=[]):
    with torch.no_grad():
        h = test_triplets[:, 0]
        r = test_triplets[:, 1]
        t = test_triplets[:, 2]
        tim = test_triplets[:, 3]
        test_size = test_triplets.shape[0]

        valid_triplets2 = torch.Tensor([[quad[0], quad[1], quad[2], quad[3]] for quad in valid_triplets2]).tolist()
        triplets_to_filter = {tuple(triplet) for triplet in valid_triplets2}

        ranks = ta_get_filtered_rank(num_entity, score, h, r, t, tim, test_size, triplets_to_filter, entity)

        ranks += 1 # change to 1-indexed

        mrr = torch.mean(1.0 / ranks.float())

        hits1 = torch.mean((ranks <= hits[0]).float())
        hits3 = torch.mean((ranks <= hits[1]).float())
        hits10 = torch.mean((ranks <= hits[2]).float())

    return mrr.item(), hits1.item(), hits3.item(), hits10.item()

